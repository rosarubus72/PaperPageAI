import os
import re
import json
import torch
import numpy as np
from pathlib import Path
from sklearn.metrics.pairwise import cosine_similarity
from transformers import (
    AutoTokenizer,
    AutoModel,
)
import shutil
import pandas as pd
from llms.llm2 import LLM2

# ==========================================================
# ğŸ”¹ è®ºæ–‡è®²è§£å†…å®¹ç”Ÿæˆå™¨ï¼ˆæ›¿ä»£åŸTweetContentAgentï¼‰
# ==========================================================
class PaperExplanationAgent:
    """ç”Ÿæˆç»“æ„åŒ–ã€ä¸“ä¸šçš„è®ºæ–‡è®²è§£å†…å®¹ï¼ˆMarkdownæ ¼å¼ï¼‰"""
    
    def __init__(self, llm_model):
        self.llm_model = llm_model
    
    def generate_paper_title(self, paper_title, abstract):
        """ç”Ÿæˆå¸å¼•äººçš„è®ºæ–‡è®²è§£æ ‡é¢˜ï¼ˆç®€æ´ã€æœ‰äº®ç‚¹ï¼‰"""
        prompt = f"""Generate an attractive title for a research paper explanation (Markdown format). Requirements:
        1. MUST include 1-2 relevant emojis at the beginning
        2. Keep it concise (10-20 words)
        3. Highlight core contribution/innovation of the paper
        4. Use professional but engaging tone
        5. Add a wave symbol ~ at the end
        
        Paper Title: {paper_title}
        Abstract: {abstract[:500]}
        
        Generate ONLY the title (no explanations, no quotes):
        """
        
        response = self.llm_model.generate(query=prompt)
        title = response.strip().strip('"').strip("'")
        
        # ç¡®ä¿æœ‰emojiï¼Œå¦‚æœæ²¡æœ‰åˆ™æ·»åŠ 
        emoji_pattern = re.compile("["
            u"\U0001F600-\U0001F64F"  # emoticons
            u"\U0001F300-\U0001F5FF"  # symbols & pictographs
            u"\U0001F680-\U0001F6FF"  # transport & map symbols
            u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
            u"\U00002702-\U000027B0"
            u"\U000024C2-\U0001F251"
            "]+", flags=re.UNICODE)
        
        if not emoji_pattern.search(title):
            # æ ¹æ®è®ºæ–‡ä¸»é¢˜æ·»åŠ åˆé€‚çš„emoji
            if any(word in paper_title.lower() for word in ['ai', 'machine', 'deep', 'neural']):
                title = f"ğŸ¤– {title}ï½"
            elif any(word in paper_title.lower() for word in ['vision', 'image', 'video', '3d']):
                title = f"ğŸ‘ï¸ {title}ï½"
            elif any(word in paper_title.lower() for word in ['language', 'text', 'nlp']):
                title = f"ğŸ—£ï¸ {title}ï½"
            elif any(word in paper_title.lower() for word in ['learning', 'model', 'algorithm']):
                title = f"ğŸ§  {title}ï½"
            else:
                title = f"ğŸ”¬ {title}ï½"
        
        # ç¡®ä¿ç»“å°¾æœ‰ï½
        if not title.endswith('ï½'):
            title = f"{title}ï½"
            
        return title
    
    def generate_paper_section(self, section_name, content, previously_generated=None):
        """ç”Ÿæˆç»“æ„åŒ–çš„è®ºæ–‡è®²è§£å†…å®¹ï¼ˆä¸“ä¸šã€ç®€æ´ï¼‰"""
        
        # ç« èŠ‚emojiæ˜ å°„ï¼ˆç®€æ´ç‰ˆï¼‰
        section_emojis = {
            "abstract": "ğŸ” Abstract",
            "motivation": "ğŸš€ Motivation",
            "innovation": "ğŸ’¡ Innovation",
            "methodology": "ğŸ› ï¸ Methodology",
            "experiments": "ğŸ“Š Experiments"
        }
        
        section_header = section_emojis.get(section_name.lower(), f"ğŸ“ {section_name.capitalize()}")
        
        # æ„å»ºé¿å…é‡å¤çš„ä¸Šä¸‹æ–‡
        context_info = ""
        if previously_generated:
            context_info = f"""
**ALREADY COVERED (DO NOT REPEAT):**
{self._summarize_previous_content(previously_generated)}

**CRITICAL: Introduce NEW information not covered above.**
"""
        
        prompt = f"""Generate professional, structured explanation for the "{section_name}" section of a research paper (Markdown format). Requirements:

**STYLE GUIDELINES (MUST FOLLOW):**
1. Professional and academic tone, no casual/conversational language
2. Use clear, concise paragraphs and bullet points (-/1.) for key points
3. Avoid exclamation marks, rhetorical questions, and overly emotional language
4. Focus on factual, objective explanation of the paper's content
5. Use proper terminology, highlight key terms with **bold**
6. Length: 200-300 words, well-organized
7. Do NOT add hashtags, emojis (except in section header), or tweet-style language

{context_info}

**Source Content:**
{content[:1000]}

Generate ONLY the section content (no section title, no markdown headers, just paragraphs/bullet points):
"""
        
        try:
            response = self.llm_model.generate(query=prompt)
            cleaned = self._clean_section_content(response)
            return cleaned
        except Exception as e:
            print(f"âŒ ç”Ÿæˆç« èŠ‚å†…å®¹å¤±è´¥: {e}")
            return self._fallback_section_content(content, section_name)
    
    def _clean_section_content(self, content):
        """æ¸…ç†ç”Ÿæˆçš„ç« èŠ‚å†…å®¹"""
        # ç§»é™¤å¯èƒ½çš„æç¤ºè¯æ®‹ç•™
        content = re.sub(r'^(è¯·ç”Ÿæˆ|ç”Ÿæˆå†…å®¹|å†…å®¹:|#+)\s*', '', content, flags=re.IGNORECASE)
        content = content.strip()
        
        # ç§»é™¤å¤šä½™çš„ç©ºè¡Œï¼Œä¿ç•™åˆç†çš„åˆ†æ®µ
        content = re.sub(r'\n\s*\n\s*\n+', '\n\n', content)
        # è§„èŒƒåŒ–åˆ—è¡¨ç¬¦å·
        content = re.sub(r'^(\d+)\. ', r'1. ', content, flags=re.MULTILINE)
        content = re.sub(r'^- ', r'- ', content, flags=re.MULTILINE)
        
        return content
    
    def _summarize_previous_content(self, previous_content):
        """æ€»ç»“å·²ç”Ÿæˆçš„å†…å®¹"""
        summary = []
        for section_name, content in previous_content.items():
            # æå–æ ¸å¿ƒä¿¡æ¯
            sentences = re.split(r'[.!?]', content)
            first_sentence = sentences[0].strip() if sentences else ""
            if first_sentence:
                summary.append(f"- {section_name}: {first_sentence}")
        
        return "\n".join(summary) if summary else "No previous content."
    
    def _fallback_section_content(self, content, section_name):
        """å¤‡ç”¨æ–¹æ³•ç”Ÿæˆç« èŠ‚å†…å®¹"""
        # ç®€åŒ–å†…å®¹ï¼Œç»“æ„åŒ–å±•ç¤º
        sentences = re.split(r'[.!?]', content)
        key_points = [s.strip() for s in sentences if s.strip()][:4]
        
        # æ„å»ºç»“æ„åŒ–å†…å®¹
        section_text = ""
        if section_name in ["motivation", "innovation", "methodology", "experiments"]:
            # ä½¿ç”¨åˆ—è¡¨å½¢å¼
            section_text = "\n".join([f"- {point}." for point in key_points])
        else:
            # æ®µè½å½¢å¼
            section_text = " ".join(key_points) + "."
        
        return section_text

# ==========================================================
# ğŸ”¹ è§†è§‰å†…å®¹é€‰æ‹©å™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰
# ==========================================================
class VisualSelector:
    """ä¸ºè®ºæ–‡è®²è§£é€‰æ‹©åˆé€‚çš„è§†è§‰å†…å®¹"""
    
    def __init__(self, llm_model):
        self.llm_model = llm_model
    
    def select_visuals(self, section_name, section_content, candidates, max_per_section=1):
        """ä¸ºç« èŠ‚é€‰æ‹©æœ€åˆé€‚çš„è§†è§‰å†…å®¹"""
        if not candidates:
            return []
        
        candidate_text = ""
        for i, (v, score) in enumerate(candidates, 1):
            vtype = "Table" if "table_path" in v else "Figure"
            cap = v.get("caption", "")
            candidate_text += f"[{i}] ({vtype}, relevance={score:.3f}) {cap[:100]}...\n"
        
        prompt = f"""Select the most relevant visual for a research paper explanation. Requirements:

**SECTION:** {section_name}
**SECTION CONTENT:** {section_content[:300]}...

**SELECTION CRITERIA:**
1. RELEVANCE: Choose visuals that directly relate to the section content
2. CLARITY: Prefer clear, easy-to-understand visuals
3. INFORMATION VALUE: Select visuals that enhance understanding of key concepts/results

**VISUAL CANDIDATES:**
{candidate_text}

**SECTION GUIDELINES:**
- For Abstract/Motivation: Choose conceptual diagrams, problem illustrations
- For Innovation: Choose novel framework diagrams, comparison visuals
- For Methodology: Choose clean architecture diagrams, process flows
- For Experiments: Choose key results tables, performance charts

Return ONLY a JSON list of indices, e.g., [1] or []
Maximum {max_per_section} visual per section.
"""
        
        try:
            resp = self.llm_model.generate(query=prompt)
            matched = json.loads(re.search(r"\[.*?\]", resp, re.S).group())
            return [candidates[i-1][0] for i in matched if 1 <= i <= len(candidates)]
        except:
            # é»˜è®¤é€‰æ‹©ç›¸å…³æ€§æœ€é«˜çš„1ä¸ª
            return [candidates[0][0]] if candidates else []

# ==========================================================
# ğŸ”¹ BGE æ¨¡å‹ï¼ˆä¿æŒä¸å˜ï¼‰
# ==========================================================
class BGEEmbedder:
    def __init__(self, model_path):
        device = torch.device("cuda:2")
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        self.model = AutoModel.from_pretrained(
            model_path, dtype=torch.float16, device_map={"": device}
        )
        self.model.eval()

    def encode(self, texts, batch_size=8):
        if isinstance(texts, str):
            texts = [texts]
        embeddings = []
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            inputs = self.tokenizer(
                batch, padding=True, truncation=True,
                return_tensors="pt", max_length=512
            ).to(self.model.device)
            with torch.no_grad():
                output = self.model(**inputs)
                batch_emb = output.last_hidden_state[:, 0, :].cpu().numpy()
            embeddings.append(batch_emb)
        return np.vstack(embeddings)

    def similarity(self, query, candidates, top_k=5):
        q_emb = self.encode([query])
        c_emb = self.encode([c["text"] for c in candidates])
        sims = cosine_similarity(q_emb, c_emb).flatten()
        top_indices = sims.argsort()[::-1][:top_k]
        return [(candidates[i], float(sims[i])) for i in top_indices]

# ==========================================================
# ğŸ”¹ è®ºæ–‡è®²è§£ç”Ÿæˆå™¨ä¸»ç±»
# ==========================================================
class PaperExplanationGenerator:
    def __init__(self, content_json_path, modules_json_path, 
                 images_json_path=None, tables_json_path=None, csv_path=None):
        self.content_json_path = content_json_path
        self.modules_json_path = modules_json_path
        self.images_json_path = images_json_path
        self.tables_json_path = tables_json_path
        self.csv_path = csv_path

        # åŠ è½½æ•°æ®
        self.paper_content = self._load_json(content_json_path)
        self.modules_content = self._load_json(modules_json_path)
        self.images_data = self._load_json(images_json_path) or {}
        self.tables_data = self._load_json(tables_json_path) or {}
        
        # åˆå§‹åŒ–LLM
        self.llm_model = LLM2('Qwen2.5-7B-Instruct')
        
        # åˆå§‹åŒ–ä»£ç†ï¼ˆæ›¿æ¢ä¸ºæ–°çš„ç”Ÿæˆå™¨ï¼‰
        self.paper_agent = PaperExplanationAgent(self.llm_model)
        self.visual_selector = VisualSelector(self.llm_model)
        self.bge = BGEEmbedder("/mnt/gaojuanru/twittergenerate/cache/huggingface/BAAI/bge-m3")
        
        self.used_visuals = set()
        self.output_assets_dir = None
        self.assets_mapping = {}
        
        # è§„åˆ’çš„ç« èŠ‚ï¼ˆå›ºå®šï¼‰
        self.planned_sections = ["abstract", "motivation", "innovation", "methodology", "experiments"]
    
    def _load_json(self, path):
        if not path or not os.path.exists(path):
            return {}
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    
    def _extract_paper_info(self):
        """æå–è®ºæ–‡åŸºæœ¬ä¿¡æ¯"""
        sections = self.paper_content.get("sections", [])
        title = sections[0].get("title", "Untitled Paper") if sections else "Untitled Paper"
        
        # æŸ¥æ‰¾æ‘˜è¦
        abstract = ""
        for section in sections:
            if "abstract" in section.get("title", "").lower():
                abstract = section.get("content", "")
                break
            elif section.get("content", "").strip():
                abstract = section.get("content", "")[:500]
                break
        
        # æå–ä½œè€…ä¿¡æ¯
        authors = []
        if sections:
            first_content = sections[0].get("content", "")
            # ç®€å•çš„ä½œè€…æå–
            author_patterns = [
                r'([A-Z][a-zA-Z\-\.]+\s+[A-Z][a-zA-Z\-\.]+)',
                r'([A-Z]\.\s*[A-Z][a-zA-Z\-]+)'
            ]
            for pattern in author_patterns:
                matches = re.findall(pattern, first_content)
                if matches:
                    authors.extend(matches)
                    if len(authors) >= 3:  # æœ€å¤šå–3ä¸ªä½œè€…
                        break
        
        return {
            "title": title,
            "abstract": abstract[:1000] if abstract else "No abstract available.",
            "authors": authors[:3] if authors else ["Anonymous"],
            "sections": sections
        }
    
    def _get_section_content(self, section_name):
        """è·å–ç« èŠ‚å†…å®¹ç”¨äºç”Ÿæˆ"""
        section_name_lower = section_name.lower()
        
        # 1. ä»modules_contentæŸ¥æ‰¾
        for module_name, module_data in self.modules_content.items():
            if section_name_lower in module_name.lower():
                return module_data.get("summary", "")
        
        # 2. ä»paper_contentæŸ¥æ‰¾
        for section in self.paper_content.get("sections", []):
            if section_name_lower in section.get("title", "").lower():
                return section.get("content", "")
        
        # 3. ä½¿ç”¨æ‘˜è¦ä½œä¸ºåå¤‡
        paper_info = self._extract_paper_info()
        return paper_info["abstract"]
    
    def _select_visuals_for_section(self, section_name, section_content):
        """ä¸ºç« èŠ‚é€‰æ‹©è§†è§‰å†…å®¹"""
        candidates = []
        
        # ä»å›¾ç‰‡æ•°æ®ä¸­æå–å€™é€‰
        for fig in self.images_data.values():
            if fig.get("image_path") and fig.get("image_path") not in self.used_visuals:
                candidates.append({
                    "text": fig.get("caption", ""),
                    "image_path": fig.get("image_path"),
                    "caption": fig.get("caption", ""),
                    "type": "image"
                })
        
        # ä»è¡¨æ ¼æ•°æ®ä¸­æå–å€™é€‰ï¼ˆä½œä¸ºå›¾ç‰‡å¤„ç†ï¼‰
        for tb in self.tables_data.values():
            if tb.get("table_path") and tb.get("table_path") not in self.used_visuals:
                candidates.append({
                    "text": tb.get("caption", "") + "\n" + tb.get("table_text", ""),
                    "image_path": tb.get("table_path"),
                    "caption": tb.get("caption", ""),
                    "type": "table"
                })
        
        if not candidates:
            return []
        
        # ä½¿ç”¨BGEè®¡ç®—ç›¸å…³æ€§
        top_candidates = self.bge.similarity(section_content, candidates, top_k=3)
        
        # é€‰æ‹©è§†è§‰å†…å®¹
        selected = self.visual_selector.select_visuals(
            section_name, section_content, top_candidates, max_per_section=1
        )
        
        # æ ‡è®°å·²ä½¿ç”¨
        for v in selected:
            self.used_visuals.add(v.get("image_path"))
        
        return selected[:1]  # æœ€å¤š1ä¸ªè§†è§‰å†…å®¹
    
    def _copy_asset(self, original_path):
        """å¤åˆ¶èµ„æºæ–‡ä»¶åˆ°è¾“å‡ºç›®å½•"""
        if not original_path or not os.path.exists(original_path):
            return None
            
        if original_path in self.assets_mapping:
            return self.assets_mapping[original_path]
        
        original_file = Path(original_path)
        new_filename = f"section_{len(self.assets_mapping)}_{original_file.name}"
        relative_path = f"assets/{new_filename}"
        
        destination = self.output_assets_dir / new_filename
        try:
            shutil.copy2(original_path, destination)
            self.assets_mapping[original_path] = relative_path
            print(f"âœ… å¤åˆ¶èµ„æº: {original_path} -> {relative_path}")
            return relative_path
        except Exception as e:
            print(f"âŒ å¤åˆ¶èµ„æºå¤±è´¥: {original_path}, é”™è¯¯: {e}")
            return None
    
    def _generate_markdown(self, paper_data):
        """ç”Ÿæˆç»“æ„åŒ–çš„Markdownæ ¼å¼è®ºæ–‡è®²è§£ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼‰"""
        # ä¸»æ ‡é¢˜
        md_content = f"# {paper_data['title']}\n\n"
        
        # ç”Ÿæˆå„ä¸ªç« èŠ‚å†…å®¹ï¼ˆç»“æ„åŒ–ï¼‰
        section_emojis = {
            "abstract": "ğŸ” Abstract",
            "motivation": "ğŸš€ Motivation",
            "innovation": "ğŸ’¡ Innovation",
            "methodology": "ğŸ› ï¸ Methodology",
            "experiments": "ğŸ“Š Experiments"
        }
        
        for section in self.planned_sections:
            if section in paper_data['sections']:
                section_data = paper_data['sections'][section]
                section_header = section_emojis.get(section.lower(), section.capitalize())
                
                # æ·»åŠ ç« èŠ‚æ ‡é¢˜
                md_content += f"### {section_header}\n"
                # æ·»åŠ ç« èŠ‚å†…å®¹
                md_content += f"{section_data['content']}\n\n"
                
                # æ·»åŠ è§†è§‰å†…å®¹ï¼ˆç®€åŒ–ç‰ˆï¼‰
                for visual in section_data.get('visuals', []):
                    if visual.get('relative_path'):
                        caption = visual.get('caption', '').strip()
                        # æ¸…ç†æ ‡é¢˜
                        caption = re.sub(r'^(Figure|Fig\.|Table|Tab\.)\s*\d+[\.:]\s*', '', caption, flags=re.IGNORECASE)
                        md_content += f"![{caption[:100]}]({visual['relative_path']})\n"
                        if caption:
                            md_content += f"> {caption}\n\n"
        
        return md_content
    
    def generate_explanation(self, output_path):
        """ç”Ÿæˆè®ºæ–‡è®²è§£Markdown"""
        print(f"ğŸš€ å¼€å§‹ç”Ÿæˆè®ºæ–‡è®²è§£...")
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        output_dir = Path(output_path).parent
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºassetsç›®å½•
        self.output_assets_dir = output_dir / "assets"
        self.output_assets_dir.mkdir(exist_ok=True)
        self.assets_mapping = {}
        
        # æå–è®ºæ–‡ä¿¡æ¯
        print("ğŸ“‹ æå–è®ºæ–‡ä¿¡æ¯...")
        paper_info = self._extract_paper_info()
        
        # ç”Ÿæˆæ ‡é¢˜
        print("ğŸ¯ ç”Ÿæˆè®²è§£æ ‡é¢˜...")
        paper_title = self.paper_agent.generate_paper_title(
            paper_info["title"], 
            paper_info["abstract"]
        )
        
        # ç”Ÿæˆå„ä¸ªéƒ¨åˆ†çš„å†…å®¹
        print("ğŸ“ ç”Ÿæˆè®²è§£å†…å®¹...")
        paper_sections = {}
        previously_generated = {}
        
        for section in self.planned_sections:
            print(f"  - å¤„ç†: {section}")
            
            # è·å–åŸºç¡€å†…å®¹
            base_content = self._get_section_content(section)
            
            # ç”Ÿæˆç»“æ„åŒ–å†…å®¹
            section_content = self.paper_agent.generate_paper_section(
                section, 
                base_content,
                previously_generated
            )
            
            # é€‰æ‹©è§†è§‰å†…å®¹
            visuals = self._select_visuals_for_section(section, section_content)
            
            # å¤åˆ¶è§†è§‰èµ„æº
            visual_data = []
            for visual in visuals:
                relative_path = self._copy_asset(visual.get("image_path"))
                if relative_path:
                    visual_data.append({
                        "relative_path": relative_path,
                        "caption": visual.get("caption", "")
                    })
            
            # å­˜å‚¨è¯¥éƒ¨åˆ†æ•°æ®
            paper_sections[section] = {
                "content": section_content,
                "visuals": visual_data
            }
            
            # è®°å½•å·²ç”Ÿæˆå†…å®¹
            previously_generated[section] = section_content
        
        # æ„å»ºè®ºæ–‡æ•°æ®
        paper_data = {
            "title": paper_title,
            "authors": paper_info["authors"],
            "sections": paper_sections
        }
        
        # ç”ŸæˆMarkdown
        print("ğŸ”„ ç”ŸæˆMarkdownæ–‡ä»¶...")
        markdown_content = self._generate_markdown(paper_data)
        
        # å†™å…¥æ–‡ä»¶
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(markdown_content)
        
        print(f"âœ… è®ºæ–‡è®²è§£ç”Ÿæˆå®Œæˆ: {output_path}")
        print(f"ğŸ“ èµ„æºæ–‡ä»¶ä¿å­˜åœ¨: {self.output_assets_dir}")
        print(f"ğŸ“Š å…±å¤åˆ¶äº† {len(self.assets_mapping)} ä¸ªèµ„æºæ–‡ä»¶")
        
        return output_path

# ==========================================================
# ğŸ”¹ æ‰¹é‡ç”Ÿæˆæ¨¡å¼
# ==========================================================
if __name__ == "__main__":
    # è®¾ç½®åŸºç¡€è·¯å¾„
    base_dir = "/home/gaojuanru/mnt_link/gaojuanru/PaperPageAI/jiexi"
    output_base_dir = "/home/gaojuanru/mnt_link/gaojuanru/PaperPageAI/paper_explanation_output"
    
    # éå†æ‰€æœ‰è®ºæ–‡å­æ–‡ä»¶å¤¹
    for subdir in sorted(os.listdir(base_dir)):
        sub_path = os.path.join(base_dir, subdir)
        if not os.path.isdir(sub_path):
            continue
        
        # è‡ªåŠ¨åŒ¹é…JSONæ–‡ä»¶
        content_json = os.path.join(sub_path, f"{subdir}_content.json")
        modules_json = os.path.join(sub_path, f"{subdir}_content_modules.json")
        images_json = os.path.join(sub_path, f"{subdir}_images.json")
        tables_json = os.path.join(sub_path, f"{subdir}_tables.json")
        
        # ç¡®ä¿è‡³å°‘æœ‰contentå’Œmodulesæ–‡ä»¶
        if not (os.path.exists(content_json) and os.path.exists(modules_json)):
            print(f"âš ï¸ ç¼ºå°‘ä¸»è¦JSONæ–‡ä»¶: {subdir}, è·³è¿‡ã€‚")
            continue
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = os.path.join(output_base_dir, subdir)
        os.makedirs(output_dir, exist_ok=True)
        
        # è¾“å‡ºæ–‡ä»¶è·¯å¾„
        output_md = os.path.join(output_dir, f"paper_explanation_{subdir}.md")
        
        print(f"\nğŸš€ æ­£åœ¨ä¸º {subdir} ç”Ÿæˆè®ºæ–‡è®²è§£...")
        
        try:
            # åˆå§‹åŒ–ç”Ÿæˆå™¨ï¼ˆæ›¿æ¢ä¸ºæ–°çš„ç±»ï¼‰
            generator = PaperExplanationGenerator(
                content_json_path=content_json,
                modules_json_path=modules_json,
                images_json_path=images_json if os.path.exists(images_json) else None,
                tables_json_path=tables_json if os.path.exists(tables_json) else None
            )
            
            # ç”Ÿæˆè®²è§£
            generator.generate_explanation(output_md)
            print(f"âœ… {subdir} è®ºæ–‡è®²è§£ç”ŸæˆæˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ {subdir} ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print("\nğŸ‰ æ‰€æœ‰è®ºæ–‡è®²è§£ç”Ÿæˆå®Œæˆ!")
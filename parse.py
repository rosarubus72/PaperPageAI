#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“„ 1parse_references_filtered.py - Docling PDFè§£æå™¨ + References å†…å®¹è¿‡æ»¤
âœ… ä½¿ç”¨ Docling ä½œä¸ºä¸»è§£æå¼•æ“
âœ… è‡ªåŠ¨è·³è¿‡ References åçš„å›¾ç‰‡ä¸è¡¨æ ¼
âœ… ä¿ç•™åŸè¾“å‡º JSON ç»“æ„ä¸å˜
"""

from dotenv import load_dotenv
import json
import os
from pathlib import Path
import re
from PIL import Image
import fitz

from docling_core.types.doc import PictureItem, TableItem
from docling.datamodel.base_models import InputFormat
from docling.datamodel.pipeline_options import PdfPipelineOptions, EasyOcrOptions
from docling.document_converter import DocumentConverter, PdfFormatOption

# ==========================================================
# GPU é…ç½®ä¸åˆå§‹åŒ–
# ==========================================================
os.environ["CUDA_VISIBLE_DEVICES"] = "2,3,4,5,6,7"
load_dotenv()

IMAGE_RESOLUTION_SCALE = 5.0

pipeline_options = PdfPipelineOptions()
pipeline_options.images_scale = IMAGE_RESOLUTION_SCALE
pipeline_options.generate_page_images = True
pipeline_options.generate_picture_images = True
pipeline_options.do_ocr = True
pipeline_options.ocr_options = EasyOcrOptions(lang=["en"])

doc_converter = DocumentConverter(
    format_options={InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)}
)

# ==========================================================
# å·¥å…·å‡½æ•°ï¼šé¡µç æ˜ å°„
# ==========================================================
def get_figure_table_page_map(pdf_path):
    """ç”¨ PyMuPDF æå–å›¾è¡¨ç¼–å·æ‰€åœ¨é¡µ"""
    page_map = {}
    recorded = set()
    with fitz.open(pdf_path) as doc:
        for i, page in enumerate(doc, start=1):
            text = page.get_text("text")
            matches = re.findall(
                r"(Table\s+\d+|Table\s+\d+:|Fig(?:ure)?\.?\s*\d+|Figure\s+\d+:)", text, flags=re.I
            )
            for m in matches:
                key = re.sub(r"[:\s\.]", "", m.lower()).replace("figure", "fig")
                if key not in recorded:
                    page_map[key] = i
                    recorded.add(key)
                    print(f"ğŸ“Œ é¦–æ¬¡è®°å½• {key} åœ¨ç¬¬ {i} é¡µ")
    return page_map

# ==========================================================
# å·¥å…·å‡½æ•°ï¼šä¿å­˜å›¾åƒï¼ˆå¢å¼ºç‰ˆï¼‰
# ==========================================================
def save_full_region_image(item, document, page_no, output_path):
    """å¢å¼ºç‰ˆå›¾åƒå¯¼å‡ºï¼šæ‰©å¤§è£åˆ‡èŒƒå›´ + fallback æ¸²æŸ“æ•´é¡µ"""
    try:
        img = item.get_image(document)
        img.save(output_path, "JPEG", quality=95)
        return True
    except Exception as e:
        print(f"âš ï¸ Docling è£å‰ªå¤±è´¥ï¼Œå°è¯• PyMuPDF æ¸²æŸ“æ•´é¡µ: {e}")
        try:
            with fitz.open(document.source_info.source_path) as doc:
                page = doc.load_page((page_no or 1) - 1)
                mat = fitz.Matrix(2, 2)
                pix = page.get_pixmap(matrix=mat)
                pix.save(output_path)
            return True
        except Exception as e2:
            print(f"âŒ æ•´é¡µæ¸²æŸ“ä¹Ÿå¤±è´¥: {e2}")
            return False

# ==========================================================
# æ–‡æœ¬è§£æ
# ==========================================================
def extract_text_sections(raw_text: str) -> dict:
    references_pattern = re.compile(
        r"(?mi)^\s*(#{0,3}\s*)?(references|bibliography)\b.*$"
    )
    references_match = references_pattern.search(raw_text)
    if references_match:
        cutoff_idx = references_match.start()
        main_text = raw_text[:cutoff_idx]
        print(f"âš ï¸ æˆªæ–­ References åå†…å®¹ï¼Œä½ç½® {cutoff_idx}")
    else:
        main_text = raw_text

    sections, title_pattern = [], re.compile(
        r"^(#{1,3}|\d+\.\s+|Chapter\s+\d+|Section\s+\d+|Fig\.\s+\d+|Table\s+\d+)\s*(.+)",
        re.IGNORECASE,
    )
    current_title, current_content = None, []

    for line in main_text.split("\n"):
        line = line.strip()
        if not line:
            continue

        # ğŸ”¹ æ–°å¢ï¼šæ£€æµ‹ Abstract æ®µè½
        if re.match(r"^(abstract)\b[\.:\s]*", line, re.IGNORECASE):
            if current_title:
                sections.append({
                    "title": current_title,
                    "content": "\n".join(current_content).strip()
                })
            current_title = "Abstract"
            current_content = [re.sub(r"^(abstract)[\.:\s]*", "", line, flags=re.I).strip()]
            continue

        match = title_pattern.match(line)
        if match:
            if current_title:
                sections.append({
                    "title": current_title,
                    "content": "\n".join(current_content).strip()
                })
            current_title, current_content = match.group(2).strip(), []
        elif current_title:
            current_content.append(line)

    if current_title:
        sections.append({"title": current_title, "content": "\n".join(current_content).strip()})
    if not sections:
        sections.append({"title": "Full Content", "content": main_text.strip()})
    return {"sections": sections}

# ==========================================================
# ä¸»å‡½æ•°
# ==========================================================
def process_pdf(pdf_path: str, output_root: str = "pdf_output"):
    pdf_name = Path(pdf_path).stem
    print(f"ğŸš€ å¼€å§‹å¤„ç† PDF: {pdf_name}")

    output_dir = Path(output_root) / pdf_name
    fig_table_dir = output_dir / "images_and_tables"
    fig_table_dir.mkdir(parents=True, exist_ok=True)

    # Docling è½¬æ¢
    try:
        conv_res = doc_converter.convert(pdf_path)
        document = conv_res.document
    except Exception as e:
        print(f"âŒ Docling è½¬æ¢å¤±è´¥: {e}")
        return

    # é¡µç æ˜ å°„
    page_map = get_figure_table_page_map(pdf_path)

    # æ–‡æœ¬ä¿å­˜
    raw_text = document.export_to_markdown()
    text_sections = extract_text_sections(raw_text)
    (output_dir / f"{pdf_name}_content.json").write_text(
        json.dumps(text_sections, ensure_ascii=False, indent=2), encoding="utf-8"
    )

    # ==========================================================
    # æ£€æµ‹ References èµ·å§‹é¡µ
    # ==========================================================
    references_page = None
    references_pattern_page = re.compile(
        r"(?mi)^\s*(references|bibliography)\b.*$"
    )
    with fitz.open(pdf_path) as doc:
        for i, page in enumerate(doc, start=1):
            text = page.get_text("text")
            if references_pattern_page.search(text):
                references_page = i
                print(f"âš ï¸ æ£€æµ‹åˆ° References èµ·å§‹äºç¬¬ {references_page} é¡µã€‚")
                break

    # ==========================================================
    # è¡¨æ ¼æå–
    # ==========================================================
    tables = {}
    print(f"ğŸ” Docling æ£€æµ‹åˆ°è¡¨æ ¼ {len(document.tables)} ä¸ª")
    for idx, table in enumerate(document.tables, 1):
        page_no = page_map.get(f"table{idx}", 0)
        if references_page and page_no >= references_page:
            print(f"â­ï¸ è·³è¿‡ References åè¡¨æ ¼ Table {idx} (ç¬¬ {page_no} é¡µ)")
            continue
        table_path = fig_table_dir / f"{pdf_name}-table-{idx}.jpg"
        if save_full_region_image(table, document, page_no, table_path):
            with Image.open(table_path) as img:
                tables[str(idx)] = {
                    "caption": table.caption_text(document) or f"Table {idx}",
                    "table_path": str(table_path),
                    "page_no": page_no,
                    "width": img.width,
                    "height": img.height,
                }

    # å¦‚æœDoclingæ²¡æœ‰æ£€æµ‹åˆ°è¡¨æ ¼ï¼Œåªè¾“å‡ºæç¤ºä¿¡æ¯
    if len(tables) == 0:
        print("âš ï¸ Docling æœªæ£€æµ‹åˆ°è¡¨æ ¼")

    (output_dir / f"{pdf_name}_tables.json").write_text(
        json.dumps(tables, ensure_ascii=False, indent=2), encoding="utf-8"
    )

    # ==========================================================
    # å›¾ç‰‡æå–
    # ==========================================================
    images = {}
    for idx, image in enumerate(document.pictures, 1):
        page_no = page_map.get(f"fig{idx}", 0)
        if references_page and page_no >= references_page:
            print(f"â­ï¸ è·³è¿‡ References åå›¾ç‰‡ Fig. {idx} (ç¬¬ {page_no} é¡µ)")
            continue
        image_path = fig_table_dir / f"{pdf_name}-picture-{idx}.jpg"
        if save_full_region_image(image, document, page_no, image_path):
            with Image.open(image_path) as img:
                images[str(idx)] = {
                    "caption": image.caption_text(document) or f"Fig. {idx}",
                    "image_path": str(image_path),
                    "page_no": page_no,
                    "width": img.width,
                    "height": img.height,
                }

    (output_dir / f"{pdf_name}_images.json").write_text(
        json.dumps(images, ensure_ascii=False, indent=2), encoding="utf-8"
    )

    print(f"ğŸ‰ å®Œæˆ {pdf_name} â†’ {output_dir}")

# ==========================================================
# å›ºå®šè·¯å¾„è¿è¡Œ
# ==========================================================
if __name__ == "__main__":
    # å›ºå®š PDF è¾“å…¥è·¯å¾„å’Œè¾“å‡ºè·¯å¾„
    pdf_path = "/home/gaojuanru/mnt_link/gaojuanru/PaperPageAI/pdf"
    output_root = "/home/gaojuanru/mnt_link/gaojuanru/PaperPageAI/jiexi"

    input_path = Path(pdf_path)
    if input_path.is_dir():
        pdf_files = sorted(input_path.glob("*.pdf"))
        for pdf in pdf_files:
            process_pdf(str(pdf), output_root)
    else:
        process_pdf(str(input_path), output_root)